package news

import (
	"crypto/sha1"
	"encoding/hex"
	"fmt"
	"log"
	"net/url"
	"regexp"
	"sort"
	"strings"
	"time"
	"unicode"

	"dknews/internal/gemini"
	"dknews/internal/metrics"
	"dknews/internal/rss"
	"dknews/internal/scraper"
)

// News represents a single news item enriched by Gemini summaries.
type News struct {
	Title     string
	Content   string
	Link      string
	Published time.Time
	Category  string
	Score     int

	SourceName       string
	SourceLang       string
	SourceCategories []string

	Summary          string // Original language summary (or detected)
	SummaryDanish    string // Danish version of summary
	SummaryUkrainian string // Ukrainian version of summary
}

// Extra boost keywords for refugee/visa related stories to increase priority
var refugeeBoostKeywords = []string{
	"refugee",
	"viborg",
	"flygtning",
	"refugee visa",
	"temporary protection",
	"asylum",
	"asylum support",
	"asylum application",
	"asylum application form",
	"asylum application form ukraine",
	"asylum application form denmark",
	"families",
	"family",
}

var visaBoostKeywords = []string{
	"visum",
	"visumforl√¶ngelse",
	"opholdstilladelse",
	"blive i EU",
}

// –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ / "—É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ" —Ç–µ—Ä–º–∏–Ω—ã (–ø—Ä–æ —Å–∞–º—É –£–∫—Ä–∞–∏–Ω—É –∏ —É–∫—Ä–∞–∏–Ω—Ü–µ–≤)
var ukraineGeoKeywords = []string{
	"ukraine", "ukraina", "ukrainer", "ukrainsk", "ukrainere", "ukrainske",
	"ukrainske familier", "ukrainske i danmark", "ukrainere i danmark",
	"ukrainsk diaspora", "flygtninge fra ukraine",
}

var denmarkKeywords = []string{
	"danmark", "danske", "k√∏benhavn", "aarhus", "aalborg", "viborg",
	"region", "kommune", "borgere", "lov", "politik", "√∏konomi",
	"visum", "opholdstilladelse", "asyl", "integration", "arbejde", "bolig",
	"udl√¶ndinge",
}

var conflictKeywords = []string{
	"krig", "krigen", "putin", "zelensky", "invasion", "bomb", "missil", "russisk", "war", "invasion",
}

// –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ / –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏ / —Å—Ç–∞—Ä—Ç–∞–ø—ã / –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
var techKeywords = []string{
	"teknologi", "innovation", "startup", "forskning", "research", "patent",
	"robot", "software", "hardware", "IT", "cloud", "cyber", "data",
	"machine learning", "deep learning", "artificial intelligence", "AI", "maskinl√¶ring", "LLM",
}

// –ò—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ AI-—Ç–µ—Ä–º–∏–Ω—ã (—á—Ç–æ–±—ã —Ç–æ—á–Ω–æ –ø–æ–π–º–∞—Ç—å –ò–ò-–Ω–æ–≤–æ—Å—Ç–∏)
var aiKeywords = []string{
	"ai", "artificial intelligence", "maskinl√¶ring", "neuralt netv√¶rk", "large language model", "llm",
}

// –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ / —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã
var medicalKeywords = []string{
	"l√¶gemidler", "medicin", "vaccine", "klinisk fors√∏g", "pharma", "biotek", "behandling", "treatment",
}

// Words to exclude (not important topics)
var excludeKeywords = []string{
	"vejr",
	"musik",
	"film",
	"kendis",
	"fodboldresultat",
	"sportsresultat",
	"tv-program",
	"horoskop",
	"madopskrift",
}

// –ï–≤—Ä–æ–ø–∞ / –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—à–∏—Ä–µ —á–µ–º –î–∞–Ω–∏—è)
var europeKeywords = []string{
	"europa", "eu", "european", "eu-lande", "europeisk",
}

// improved containsAny: distinguishes phrases and short words (avoids "ai" matching "said")
func containsAny(text string, keywords []string) bool {
	text = strings.ToLower(text)

	for _, k := range keywords {
		k = strings.ToLower(strings.TrimSpace(k))
		if k == "" {
			continue
		}

		// If keyword is a phrase (contains space) -> substring match
		if strings.Contains(k, " ") {
			if strings.Contains(text, k) {
				return true
			}
			continue
		}

		// Short tokens (<=3) -> whole word match using word boundary regexp
		if len(k) <= 3 {
			// Use regexp.QuoteMeta to avoid accidental meta-chars in keyword
			re := regexp.MustCompile(`\b` + regexp.QuoteMeta(k) + `\b`)
			if re.MatchString(text) {
				return true
			}
			continue
		}

		// Otherwise, simple substring is fine
		if strings.Contains(text, k) {
			return true
		}
	}
	return false
}

// makeNewsKey generates a hash key from title and description for deduplication
func makeNewsKey(title, description string) string {
	h := sha1.New()
	h.Write([]byte(strings.ToLower(title + description)))
	return hex.EncodeToString(h.Sum(nil))
}

// makeSimilarityKey creates a more lenient key for detecting similar news
// makeSimilarityKey - –º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è.
// –õ–æ–≥–∏–∫–∞:
// 1) –ë–µ—Ä—ë–º host –∏–∑ item.Link (–µ—Å–ª–∏ –µ—Å—Ç—å) ‚Äî —á—Ç–æ–±—ã –∫–ª—é—á –±—ã–ª —Å–ø–µ—Ü–∏—Ñ–∏—á–µ–Ω –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
// 2) –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫: lowercase, —É–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, —É–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞.
// 3) –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ N –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 6) ‚Äî —á—Ç–æ–±—ã –Ω–µ —Å–∫–ª–µ–∏–≤–∞—Ç—å —Å–ª–∏—à–∫–æ–º —Ä–∞–∑–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏.
// 4) –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ä–µ–∑ (truncate –ø–æ –æ–∫–Ω—É –≤ hours, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 6—á).
// –†–µ–∑—É–ª—å—Ç–∞—Ç: host|topWords|windowUnix
func makeSimilarityKey(item *rss.FeedItem) string {
	// –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å
	const (
		windowHours = 6 // –æ–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –¥–µ–¥—É–ø–∞ (–º–µ–Ω—å—à–µ -> –º–µ–Ω—å—à–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç–∏)
		maxWords    = 6 // —Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ –æ—Å—Ç–∞–≤–∏—Ç—å
	)

	// Helper: –ø–æ–ª—É—á–∏—Ç—å host –∏–∑ —Å—Å—ã–ª–∫–∏
	getHost := func(link string) string {
		if link == "" {
			return "unknown"
		}
		u, err := url.Parse(link)
		if err != nil || u.Host == "" {
			// –∏–Ω–æ–≥–¥–∞ –≤ feed –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ª–∏–Ω–∫ –∏–ª–∏ –ø—É—Å—Ç–æ–π
			return "unknown"
		}
		return strings.ToLower(u.Host)
	}

	// Helper: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ‚Äî —É–±—Ä–∞—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, multiple spaces, lower
	normalize := func(s string) string {
		s = strings.ToLower(s)
		// —É–¥–∞–ª–∏—Ç—å HTML-—Ç–µ–≥–∏ –µ—Å–ª–∏ –≤–¥—Ä—É–≥
		reTags := regexp.MustCompile(`<[^>]*>`)
		s = reTags.ReplaceAllString(s, " ")

		// –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±–µ–ª—ã (Unicode-aware)
		var b []rune
		b = make([]rune, 0, len(s))
		for _, r := range s {
			if unicode.IsLetter(r) || unicode.IsNumber(r) || unicode.IsSpace(r) {
				b = append(b, r)
			} else {
				// –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª, —á—Ç–æ–±—ã —Ä–∞–∑–¥–µ–ª—è—Ç—å —Å–ª–æ–≤–∞
				b = append(b, ' ')
			}
		}
		out := strings.Join(strings.Fields(string(b)), " ")
		return out
	}

	// –ù–µ–±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä —Å—Ç–æ–ø-—Å–ª–æ–≤ ‚Äî —Ä–∞—Å—à–∏—Ä—è–π –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (–¥–∞—Ç—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
	stopWords := map[string]bool{
		"a": true, "an": true, "the": true, "og": true, "i": true, "p√•": true,
		"til": true, "af": true, "med": true, "for": true, "er": true, "der": true,
		"om": true, "en": true, "et": true, "ikke": true,
	}

	// –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç: title + short description
	text := strings.TrimSpace(item.Title + " " + item.Description)
	norm := normalize(text)
	words := strings.Fields(norm)

	// –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ ¬´–∑–Ω–∞—á–∏–º—ã–µ¬ª —Å–ª–æ–≤–∞
	significant := make([]string, 0, len(words))
	for _, w := range words {
		if len(significant) >= maxWords {
			break
		}
		if stopWords[w] {
			continue
		}
		// –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (<=2)
		if len(w) <= 2 {
			continue
		}
		significant = append(significant, w)
	}
	// –ï—Å–ª–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ ‚Äî –≤–æ–∑—å–º—ë–º –ø–µ—Ä–≤—ã–µ maxWords –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ (–±–µ–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
	if len(significant) == 0 && len(words) > 0 {
		for i := 0; i < len(words) && i < maxWords; i++ {
			significant = append(significant, words[i])
		}
	}

	// –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ä–µ–∑: –∏—Å–ø–æ–ª—å–∑—É–µ–º PublishedParsed –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ —Ç–µ–∫—É—â–∏–π —á–∞—Å
	var t time.Time
	if item.PublishedParsed != nil {
		t = *item.PublishedParsed
	} else if item.Published != "" {
		// –ø–æ–ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å Published (–±–µ–∑ –≥–∞—Ä–∞–Ω—Ç–∏–π) ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback
		if parsed, err := time.Parse(time.RFC1123Z, item.Published); err == nil {
			t = parsed
		} else if parsed2, err2 := time.Parse(time.RFC1123, item.Published); err2 == nil {
			t = parsed2
		} else {
			t = time.Now()
		}
	} else {
		t = time.Now()
	}
	// –û–±—Ä–µ–∑–∞–µ–º –≤—Ä–µ–º—è –¥–æ –Ω–∞—á–∞–ª–∞ –æ–∫–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 6—á)
	windowStart := t.Truncate(time.Duration(windowHours) * time.Hour).Unix()

	host := getHost(item.Link)

	// –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–ª—é—á
	key := fmt.Sprintf("%s|%s|%d", host, strings.Join(significant, "_"), windowStart)
	return key
}

// calculateNewsScore - –Ω–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏–∏
// calculateNewsScore - –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏–∏
func calculateNewsScore(item *rss.FeedItem) (string, int) {
	text := strings.ToLower(item.Title + " " + item.Description)

	// –ë—ã—Å—Ç—Ä–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
	if containsAny(text, excludeKeywords) {
		return "", 0
	}

	// –§–ª–∞–≥–∏
	hasDenmark := containsAny(text, denmarkKeywords)
	hasUkraineGeo := containsAny(text, ukraineGeoKeywords)
	hasEurope := containsAny(text, europeKeywords)
	hasTech := containsAny(text, techKeywords) || containsAny(text, aiKeywords)
	hasMedical := containsAny(text, medicalKeywords)
	hasConflict := containsAny(text, conflictKeywords)
	hasRefugeeBoost := containsAny(text, refugeeBoostKeywords)
	hasVisaBoost := containsAny(text, visaBoostKeywords)

	// –ï—Å–ª–∏ —ç—Ç–æ —Ç–æ–ª—å–∫–æ "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ" —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤–æ–π–Ω—ã/–ø—É—Ç–∏–Ω –∏ –ù–ï–¢ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.
	if hasConflict && !(hasDenmark || hasUkraineGeo || hasEurope) {
		return "", 0
	}

	// –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
	var category string
	score := 0

	// 1) –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏/–ò–ò/–º–µ–¥–∏—Ü–∏–Ω—É ‚Äî —Ç—Ä–µ–±—É–µ–º –≥–µ–æ-–∫–æ–Ω—Ç–µ–∫—Å—Ç
	if hasTech || hasMedical {
		if !(hasDenmark || hasUkraineGeo || hasEurope) {
			// —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è/–º–µ–¥–∏—Ü–∏–Ω–∞ –±–µ–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø—Ä–∏–≤—è–∑–∫–∏ ‚Äî –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ
			return "", 0
		}
		if hasMedical {
			category = "health"
		} else {
			category = "tech"
		}
		score = 80
		// AI-–ø—Ä–µ–º–∏—è
		if containsAny(text, aiKeywords) {
			score += 10
		}
		// –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–¥–µ—Å—å ‚Äî –¥–∞—ë–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –±–æ–Ω—É—Å—ã –Ω–∏–∂–µ
	}

	// 2) –ù–æ–≤–æ—Å—Ç–∏ –ø—Ä–æ —É–∫—Ä–∞–∏–Ω—Ü–µ–≤ / –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∂–µ–Ω—Ü–µ–≤ / –≤–∏–∑—ã ‚Äî –≤—ã—Å–æ–∫–∞—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ—Å—Ç—å
	if hasUkraineGeo || hasRefugeeBoost || hasVisaBoost {
		// –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –µ—â—ë –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (–Ω–µ tech/health), —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å "ukraine"
		if category == "" {
			category = "ukraine"
			score = 70
		} else {
			// –µ—Å–ª–∏ —É–∂–µ tech/health ‚Äî —É—Å–∏–ª–∏–≤–∞–µ–º score –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
			score += 5
		}
		// –ª–æ–∫–∞–ª—å–Ω—ã–µ –±–æ–Ω—É—Å—ã
		if hasDenmark {
			score += 15
		}
		if hasEurope {
			score += 5
		}
		// –û—Ç–∫–∞—Ç "–≤–æ–π–Ω—ã" –∫–∞–∫ –≥–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä, –µ—Å–ª–∏ –∫—Ä–æ–º–µ –Ω–µ—ë –Ω–µ—Ç —Å–æ—Ü/–≤–∏–∑—ã/–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
		if hasConflict && !(hasRefugeeBoost || hasVisaBoost || hasDenmark) {
			score -= 15
		}
		// –í–æ–∑–≤—Ä–∞—â–∞–µ–º, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ —É–∂–µ —è–≤–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –±–ª–æ–∫
		return category, score
	}

	// 3) –û–±—â–∏–µ –¥–∞—Ç—Å–∫–∏–µ/–µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
	if hasDenmark || hasEurope {
		// –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ ‚Äî —Å–¥–µ–ª–∞—Ç—å denmark
		if category == "" {
			category = "denmark"
			score = 40
		}
		// –º–∞–ª–µ–Ω—å–∫–∏–π –±–æ–Ω—É—Å –∑–∞ –ø–æ–ª–∏—Ç–∏–∫—É/—ç–∫–æ–Ω–æ–º–∏–∫—É
		if containsAny(text, []string{"politik", "regering", "√∏konomi", "minister"}) {
			score += 15
		}
		// –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ/–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤—Å—Ç–∞–≤–∫–∏ —É—Å–∏–ª–∏–≤–∞—é—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è "denmark"
		if hasTech && category != "tech" {
			score += 10
		}
		if hasMedical && category != "health" {
			score += 10
		}
		// –±–æ–Ω—É—Å—ã –¥–ª—è –≤–∏–∑/–±–µ–∂–µ–Ω—Ü–µ–≤
		if hasRefugeeBoost {
			score += 20
		}
		if hasVisaBoost {
			score += 25
		}
		// –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —Ç–∞–∫–∂–µ –µ—Å—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Äî –Ω–µ–º–Ω–æ–≥–æ —Å–Ω–∏–∑–∏–º
		if hasConflict {
			score -= 5
		}
		// –∫–æ–Ω–µ—Ü –≤–µ—Ç–∫–∏
		return category, score
	}

	// 4) –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –≤—Å—ë –µ—â—ë –ø—É—Å—Ç–∞—è ‚Äî –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ
	if category == "" {
		return "", 0
	}

	// 5) –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (—Ç–æ–ª—å–∫–æ tech/health –ø—É—Ç—å –æ—Å—Ç–∞–≤–∞–ª—Å—è), –ø—Ä–∏–º–µ–Ω–∏–º –æ–±—â–∏–µ –±–æ–Ω—É—Å—ã

	// –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π —Å–∫–æ—Ä
	if score < 0 {
		score = 0
	}

	return category, score
}

// Gemini client injection
var aiClient *gemini.Client

// SetGeminiClient sets the Gemini client for translation and summarization
func SetGeminiClient(c *gemini.Client) {
	aiClient = c
}

// FilterAndTranslate now: filter + scrape + Gemini summarize + multi-language summary.
func FilterAndTranslate(items []*rss.FeedItem) ([]News, error) {
	startTime := time.Now()
	defer func() {
		metrics.Global.RecordProcessingTime(time.Since(startTime))
		metrics.Global.SetLastRun()
	}()

	if aiClient == nil {
		return nil, fmt.Errorf("gemini client not initialized; call news.SetGeminiClient")
	}
	log.Println("[Gemini] Starting filter + scrape + summarize pipeline (TranslateAndSummarizeNews)")

	seenLinks := map[string]struct{}{}
	seenContent := map[string]struct{}{}
	seenSimilar := map[string]struct{}{} // –ù–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏
	var candidates []News

	log.Printf("–ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∏–∑ %d –Ω–æ–≤–æ—Å—Ç–µ–π", len(items))

	for _, item := range items {
		metrics.Global.IncrementNewsProcessed()

		// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞)
		if item.PublishedParsed != nil && time.Since(*item.PublishedParsed) > 24*time.Hour {
			continue
		}

		// –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Å—Å—ã–ª–∫–µ
		if _, dup := seenLinks[item.Link]; dup {
			log.Printf("üîó –î—É–±–ª–∏–∫–∞—Ç –ø–æ —Å—Å—ã–ª–∫–µ: %s", item.Title)
			metrics.Global.IncrementDuplicatesFiltered()
			continue
		}
		seenLinks[item.Link] = struct{}{}

		// –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é (–∑–∞–≥–æ–ª–æ–≤–æ–∫ + –æ–ø–∏—Å–∞–Ω–∏–µ)
		key := makeNewsKey(item.Title, item.Description)
		if _, dup := seenContent[key]; dup {
			log.Printf("üìÑ –î—É–±–ª–∏–∫–∞—Ç –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é: %s", item.Title)
			metrics.Global.IncrementDuplicatesFiltered()
			continue
		}
		seenContent[key] = struct{}{}

		// –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è)
		similarKey := makeSimilarityKey(item)
		if _, dup := seenSimilar[similarKey]; dup {
			log.Printf("üîÑ –ü–æ—Ö–æ–∂–∞—è –Ω–æ–≤–æ—Å—Ç—å (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º): %s", item.Title)
			metrics.Global.IncrementDuplicatesFiltered()
			continue
		}
		seenSimilar[similarKey] = struct{}{}

		// –í—ã—á–∏—Å–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –≤–∞–∂–Ω–æ—Å—ÇÔøΩÔøΩ
		category, score := calculateNewsScore(item)
		if score == 0 {
			continue // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
		}

		published := time.Now()
		if item.PublishedParsed != nil {
			published = *item.PublishedParsed
		}

		sourceName, sourceLang := "", ""
		var sourceCategories []string
		if item.Source != nil {
			sourceName = item.Source.Name
			sourceLang = item.Source.Lang
			sourceCategories = item.Source.Categories
		}

		candidates = append(candidates, News{
			Title:            item.Title,
			Content:          item.Description, // –ü–æ–∫–∞ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ–±–∞–≤–∏–º –ø–æ—Å–ª–µ
			Link:             item.Link,
			Published:        published,
			Category:         category,
			Score:            score,
			SourceName:       sourceName,
			SourceLang:       sourceLang,
			SourceCategories: sourceCategories,
		})

		log.Printf("–î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å [%s, score:%d, source:%s]: %s", category, score, sourceName, item.Title)
	}

	// sort
	sort.Slice(candidates, func(i, j int) bool {
		if candidates[i].Score != candidates[j].Score {
			return candidates[i].Score > candidates[j].Score // –ü–æ —É–±—ã–≤–∞–Ω–∏—é –≤–∞–∂–Ω–æ—Å—Ç–∏
		}
		return candidates[i].Published.After(candidates[j].Published) // –ü–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
	})

	newsLimit := 8
	if len(candidates) < newsLimit {
		newsLimit = len(candidates)
	}
	urls := make([]string, newsLimit)
	for i := 0; i < newsLimit; i++ {
		urls[i] = candidates[i].Link
	}

	log.Printf("–ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç %d —Å—Ç–∞—Ç–µ–π...", newsLimit)
	fullArticles := scraper.ExtractArticlesInBackground(urls)

	res := make([]News, 0, newsLimit)
	for i := 0; i < newsLimit; i++ {
		n := candidates[i]
		if fa, ok := fullArticles[n.Link]; ok && len(fa.Content) > 200 {
			n.Content = fa.Content
			log.Printf("‚úÖ –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (%d) –¥–ª—è: %s", len(n.Content), n.Title)
		} else {
			log.Printf("‚ö†Ô∏è –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è: %s", n.Title)
		}

		log.Printf("Gemini summary %d/%d: %s", i+1, newsLimit, n.Title)
		aiResp, err := aiClient.TranslateAndSummarizeNews(n.Title, n.Content)
		if err != nil {
			log.Printf("‚ùå Gemini error: %v", err)
			n.Summary = fallbackSummary(n.Content)
			n.SummaryDanish = "(Ingen AI)"
			n.SummaryUkrainian = "(–ù–µ–º–∞—î AI)"
		} else {
			n.Summary = aiResp.Summary
			n.SummaryDanish = aiResp.Danish
			n.SummaryUkrainian = aiResp.Ukrainian
		}
		res = append(res, n)
	}

	log.Printf("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ %d –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π", len(res))
	return res, nil
}

func fallbackSummary(content string) string {
	c := strings.TrimSpace(content)
	if c == "" {
		return "(–ù–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞)"
	}
	sentences := strings.Split(c, ".")
	var picked []string
	for _, s := range sentences {
		s = strings.TrimSpace(s)
		if len(s) < 25 {
			continue
		}
		picked = append(picked, s)
		if len(picked) >= 2 {
			break
		}
	}
	if len(picked) == 0 {
		if len(c) > 160 {
			return c[:160] + "..."
		}
		return c
	}
	return strings.Join(picked, ". ") + "."
}

// FormatNews produces concise formatted output with summaries.
func FormatNews(n News) string {
	var b strings.Builder
	b.WriteString("üá©üá∞ *" + n.Title + "*\n")
	if n.SummaryUkrainian != "" {
		b.WriteString("üá∫üá¶ " + n.SummaryUkrainian + "\n")
	}
	if n.SummaryDanish != "" {
		b.WriteString("üá©üá∞ " + n.SummaryDanish + "\n")
	}
	b.WriteString("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
	return b.String()
}
